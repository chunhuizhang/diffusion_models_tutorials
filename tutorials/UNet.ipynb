{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c66d3168",
   "metadata": {},
   "source": [
    "- https://arxiv.org/abs/1505.04597\n",
    "    - U-Net: Convolutional Networks for Biomedical Image Segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2224488a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T14:24:21.332166Z",
     "start_time": "2024-03-05T14:24:19.802910Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9111df8",
   "metadata": {},
   "source": [
    "## basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793974f8",
   "metadata": {},
   "source": [
    "- image input image output\n",
    "    - 最开始要解决的是医学图像分割（medical image segmentation）\n",
    "        - input：image, output：segmentation masks\n",
    "\n",
    "    $$\n",
    "    \\text{MSE}=\\frac1n\\sum_{i=1}^n(Y_i - \\hat Y_i)^2\n",
    "    $$\n",
    "\n",
    "    - 还可以用于图像超分辨率（high resolution）\n",
    "    - diffusion models\n",
    "- unet: encoder & decoder\n",
    "    - encoder: extracting features from input images\n",
    "    - decoder: up sampling intermediate features and producing the final output\n",
    "    - encoder & decoder are symmetrical and connected by paths\n",
    "        - U-shape Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301ac64b",
   "metadata": {},
   "source": [
    "## architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747ae238",
   "metadata": {},
   "source": [
    "- encoder\n",
    "    - Repeated 3*3 conv + ReLU layers\n",
    "        - 572 \\* 572 -> 570 \\* 570 -> 568 \\* 568\n",
    "    - 2*2 maxpooling layers to downsample\n",
    "        - 568 -> 284\n",
    "        - 280 -> 140\n",
    "    - double channels with conv after maxpooling\n",
    "        - 64 -> 128 -> 256\n",
    "- decoder\n",
    "    - repeated 3*3 conv + ReLU layers\n",
    "    - Upsampling, followed by 2*2 conv layer\n",
    "    - halve channels after upsampling conv\n",
    "- connections: bottleneck & connecting paths\n",
    "    - bottleneck\n",
    "    - connecting paths：\n",
    "        - 添加 encoder 的细节信息；\n",
    "        - 实现上，在 depth/channels 上做拼接；\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "249967ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T13:35:06.011960Z",
     "start_time": "2024-03-05T13:35:05.995309Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://huggingface.co/blog/assets/78_annotated-diffusion/unet_architecture.jpg\" width=\"700\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://arxiv.org/abs/1505.04597\n",
    "Image(url='https://huggingface.co/blog/assets/78_annotated-diffusion/unet_architecture.jpg', width=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba51bd01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T13:35:09.427818Z",
     "start_time": "2024-03-05T13:35:09.416906Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://camo.githubusercontent.com/2c676413dda1f487521dd5c1e5c4b35b8cfbf06d50880e15660ea44bd76eac6f/68747470733a2f2f68756767696e67666163652e636f2f64617461736574732f68756767696e67666163652f646f63756d656e746174696f6e2d696d616765732f7265736f6c76652f6d61696e2f756e65742d6d6f64656c2e706e67\" width=\"600\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://camo.githubusercontent.com/2c676413dda1f487521dd5c1e5c4b35b8cfbf06d50880e15660ea44bd76eac6f/68747470733a2f2f68756767696e67666163652e636f2f64617461736574732f68756767696e67666163652f646f63756d656e746174696f6e2d696d616765732f7265736f6c76652f6d61696e2f756e65742d6d6f64656c2e706e67', \n",
    "              width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54b0cfa",
   "metadata": {},
   "source": [
    "## UNet from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "971ee914",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T14:25:08.725776Z",
     "start_time": "2024-03-05T14:25:08.706815Z"
    }
   },
   "outputs": [],
   "source": [
    "class BasicUNet(nn.Module):\n",
    "    \"\"\"A minimal UNet implementation.\"\"\"\n",
    "    def __init__(self, in_channels=1, out_channels=1):\n",
    "        super().__init__()\n",
    "        self.down_layers = torch.nn.ModuleList([ \n",
    "            nn.Conv2d(in_channels, 32, kernel_size=5, padding=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=5, padding=2),\n",
    "            nn.Conv2d(64, 64, kernel_size=5, padding=2),\n",
    "        ])\n",
    "        self.up_layers = torch.nn.ModuleList([\n",
    "            nn.Conv2d(64, 64, kernel_size=5, padding=2),\n",
    "            nn.Conv2d(64, 32, kernel_size=5, padding=2),\n",
    "            nn.Conv2d(32, out_channels, kernel_size=5, padding=2), \n",
    "        ])\n",
    "        self.act = nn.SiLU() # The activation function\n",
    "        self.downscale = nn.MaxPool2d(2)\n",
    "        self.upscale = nn.Upsample(scale_factor=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = []\n",
    "        for i, l in enumerate(self.down_layers):\n",
    "            x = self.act(l(x)) # Through the layer and the activation function\n",
    "            if i < 2: # For all but the third (final) down layer:\n",
    "                h.append(x) # Storing output for skip connection\n",
    "                x = self.downscale(x) # Downscale ready for the next layer\n",
    "              \n",
    "        for i, l in enumerate(self.up_layers):\n",
    "            if i > 0: # For all except the first up layer\n",
    "                x = self.upscale(x) # Upscale\n",
    "                x += h.pop() # Fetching stored output (skip connection)\n",
    "            x = self.act(l(x)) # Through the layer and the activation function\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72e9f44b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T14:26:03.520370Z",
     "start_time": "2024-03-05T14:26:03.466155Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 28, 28])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet = BasicUNet()\n",
    "x = torch.rand(8, 1, 28, 28)\n",
    "unet(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7ef2e30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T14:32:53.409476Z",
     "start_time": "2024-03-05T14:32:53.402697Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade torchsummary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73407f42",
   "metadata": {},
   "source": [
    "- (Conv2d, silu, maxpool) \\* 2\n",
    "    - (1, 28, 28) => **(32, 28, 28)** => (32, 14, 14)\n",
    "    - (32, 14, 14) => **(64, 14, 14)** => (64, 7, 7)\n",
    "- (Conv2d, silu)\n",
    "    - (64, 7, 7) => (64, 7, 7)\n",
    "- (conv2d, silu)\n",
    "    - (64, 7, 7) => (64, 7, 7)\n",
    "- (upsample, Conv2d, silu) \\* 2\n",
    "    - (64, 7, 7) => **(64, 14, 14)** => (32, 14, 14)\n",
    "    - (32, 14, 14) => **(32, 28, 28)** => (1, 28, 28)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87cb4575",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T14:46:32.693503Z",
     "start_time": "2024-03-05T14:46:32.682655Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "309057"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in unet.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "595f3ffe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T14:28:12.567366Z",
     "start_time": "2024-03-05T14:28:12.540244Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 28, 28]             832\n",
      "              SiLU-2           [-1, 32, 28, 28]               0\n",
      "         MaxPool2d-3           [-1, 32, 14, 14]               0\n",
      "            Conv2d-4           [-1, 64, 14, 14]          51,264\n",
      "              SiLU-5           [-1, 64, 14, 14]               0\n",
      "         MaxPool2d-6             [-1, 64, 7, 7]               0\n",
      "            Conv2d-7             [-1, 64, 7, 7]         102,464\n",
      "              SiLU-8             [-1, 64, 7, 7]               0\n",
      "            Conv2d-9             [-1, 64, 7, 7]         102,464\n",
      "             SiLU-10             [-1, 64, 7, 7]               0\n",
      "         Upsample-11           [-1, 64, 14, 14]               0\n",
      "           Conv2d-12           [-1, 32, 14, 14]          51,232\n",
      "             SiLU-13           [-1, 32, 14, 14]               0\n",
      "         Upsample-14           [-1, 32, 28, 28]               0\n",
      "           Conv2d-15            [-1, 1, 28, 28]             801\n",
      "             SiLU-16            [-1, 1, 28, 28]               0\n",
      "================================================================\n",
      "Total params: 309,057\n",
      "Trainable params: 309,057\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.14\n",
      "Params size (MB): 1.18\n",
      "Estimated Total Size (MB): 2.32\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(unet, input_size=(1, 28, 28), device='cpu')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
