{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72185ab3-d173-430b-8ee2-137995311c6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T03:11:08.335257Z",
     "iopub.status.busy": "2025-01-19T03:11:08.334601Z",
     "iopub.status.idle": "2025-01-19T03:11:08.344158Z",
     "shell.execute_reply": "2025-01-19T03:11:08.341963Z",
     "shell.execute_reply.started": "2025-01-19T03:11:08.335207Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203ea35e-d6bb-4870-aef6-d6afd2b8471e",
   "metadata": {},
   "source": [
    "- DGM（Deep Generative Modelling），深度生成模型\n",
    "    - https://www.youtube.com/watch?v=JlmOZZnjzOg\n",
    "    - https://jmtomczak.github.io/blog/4/4_VAE.html\n",
    "- https://arxiv.org/pdf/1312.6114\n",
    "    - Kingma: Adam, Anthropic\n",
    "- https://github.com/lyeoni/pytorch-mnist-VAE\n",
    "- https://towardsdatascience.com/difference-between-autoencoder-ae-and-variational-autoencoder-vae-ed7be1c038f2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda7c14b-2a39-43df-bd57-a083cf05ed0f",
   "metadata": {},
   "source": [
    "### LDM (latent variable models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf29d75f-b572-469b-b2b4-bd2537bf2737",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T03:11:27.516136Z",
     "iopub.status.busy": "2025-01-19T03:11:27.515553Z",
     "iopub.status.idle": "2025-01-19T03:11:27.527770Z",
     "shell.execute_reply": "2025-01-19T03:11:27.525701Z",
     "shell.execute_reply.started": "2025-01-19T03:11:27.516085Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://jmtomczak.github.io/blog/4/lvm_diagram.png\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://jmtomczak.github.io/blog/4/lvm_diagram.png', width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ac407a-ace6-4606-80d6-15e1e16ee2c7",
   "metadata": {},
   "source": [
    "- 隐变量模型\n",
    "    - 感兴趣的高维对象 $x\\in \\mathcal X^D$，对于图像，$\\mathcal X\\in\\{0,1,\\cdots,255\\}$\n",
    "        - $p(x)$: data distribution\n",
    "    - 低维隐变量，$z\\in \\mathcal Z^M$ ($\\mathcal Z=\\mathbb R$)，将 $\\mathcal Z^M$ 称为高维空间的低维流形；\n",
    "- 生成过程\n",
    "    - $z\\sim p_\\lambda(z)$: 红色部分，采样 sampling\n",
    "    - $x\\sim p_\\theta(x|z)$: 蓝色部分，生成 generating\n",
    "    - 概率建模\n",
    "        - 引入隐变量 $z$ 的联合分布：$p(x,z)=p(z)p(x|z)$\n",
    "- training，我们只能访问 $x$，我们将未知的部分 $z$ sum out / margin out（积分积掉）\n",
    "    - $p(x)=\\int p(x,z)dz=\\int p(x|z)p(z)dz$\n",
    "        - $p(z)=\\int p(x,z)dx$\n",
    "        - $p(x|z)=\\frac{p(x,z)}{p(z)}$\n",
    "        - $p(z|x)=\\frac{p(x,z)}{p(x)}$\n",
    "    - VAE 就是解决这个复杂积分的方法；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f006c4-697a-4647-b69d-1837d3fb0568",
   "metadata": {},
   "source": [
    "### vae recap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03993bf5-b678-41ab-aab5-40c63bf34974",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T03:28:43.583346Z",
     "iopub.status.busy": "2025-01-19T03:28:43.582768Z",
     "iopub.status.idle": "2025-01-19T03:28:43.595543Z",
     "shell.execute_reply": "2025-01-19T03:28:43.593480Z",
     "shell.execute_reply.started": "2025-01-19T03:28:43.583296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./imgs/vae_px.png\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='./imgs/vae_px.png', width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225faf0f-4d94-4d93-8a42-f621a0dd8a67",
   "metadata": {},
   "source": [
    "- VAE: Variational posterior (encoder, $(q(z|x))$) and likelihood function (decoder) are parameterized by NNs;\n",
    "    - posterior: $q(z|x) \\approx p(z|x)$\n",
    "        - $q(z|x)=\\mathcal N(\\mu, \\sigma^2)$\n",
    "        - $p(z)=\\mathcal N(0, 1)$\n",
    "        - $KL(q(z|x)|p(z))=KL(\\mathcal N(\\mu, \\sigma)|\\mathcal N(0, I))=-\\frac12(1+\\log(\\sigma^2)-\\mu^2-\\sigma^2)$\n",
    "    - likelihood: $p(x|z)$\n",
    "        - $\\mathbb E_{q(z|x)}[\\log p(x|z)]$\n",
    "    - $\\mathcal L(x)=\\mathbb E_{q(z|x)}[\\log p(x|z)]-KL(q(z|x)|p(z))$\n",
    "- Variational autoencoder addresses the issue of **non-regularized latent space** in autoencoder and provides the **generative capability** to the entire space.\n",
    "    - AutoEncoder 不是生成模型（是用来做压缩重构的），VAE 是生成模型；\n",
    "    - VAE 训练是学习数据的概率分布，生成是基于从该概率分布中采样的点；\n",
    "        - `mu, log_var = self.encoder(x.view(-1, 784))`\n",
    "        - VAE 假设每个输入数据点在潜在空间中对应一个正态分布，而不是一个点\n",
    "    - The encoder in the AE outputs **latent vectors**.\n",
    "    - Instead of outputting the vectors in the latent space, the encoder of VAE outputs **parameters of a pre-defined distribution** in the latent space for every input.\n",
    "        - The VAE then imposes a constraint on this latent distribution forcing it to be **a normal distribution**. This constraint makes sure that the latent space is regularized.\n",
    "- loss function\n",
    "    - KL: regularization\n",
    "  - sum of batch\n",
    "      - `recon_x.shape`: (bs, 784)\n",
    "      - `log_var/mu.shape`: (bs, 2)\n",
    "    ```\n",
    "    def loss_function(recon_x, x, mu, log_var):\n",
    "        BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "        KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        return BCE, KLD\n",
    "    ```\n",
    "- latent space dimension\n",
    "    - $\\mu, \\log(\\sigma^2)$\n",
    "    - 维度可调\n",
    "    - $p(z)=\\mathcal N(0, I)$\n",
    "    - 显然更高的维度，意味着更低的 bce loss（也许更高的 kld loss）\n",
    "        - 2维只是为了可视化和后续生成的方便\n",
    "- encode & sample & decode\n",
    "    - z = mu + std*eps\n",
    "        - $\\eps\\sim \\mathcal N(0, I)$\n",
    "    ```\n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encoder(x.view(-1, 784))\n",
    "        z = self.sampling(mu, log_var)\n",
    "        return self.decoder(z), mu, log_var\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1110c77d-5730-412f-996d-0cbf2b506c88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T03:37:19.696010Z",
     "iopub.status.busy": "2025-01-19T03:37:19.695434Z",
     "iopub.status.idle": "2025-01-19T03:37:19.707175Z",
     "shell.execute_reply": "2025-01-19T03:37:19.705246Z",
     "shell.execute_reply.started": "2025-01-19T03:37:19.695961Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./imgs/ae_nn.png\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='./imgs/ae_nn.png', width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "218dabf9-9d6a-4c2a-9a4e-780cb7c7ecc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T03:36:05.371212Z",
     "iopub.status.busy": "2025-01-19T03:36:05.370633Z",
     "iopub.status.idle": "2025-01-19T03:36:05.383529Z",
     "shell.execute_reply": "2025-01-19T03:36:05.381455Z",
     "shell.execute_reply.started": "2025-01-19T03:36:05.371162Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./imgs/vae_nn.png\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='./imgs/vae_nn.png', width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c525174e-0f08-49b4-9fbf-4013155f870b",
   "metadata": {},
   "source": [
    "### latent space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb2f2df-cc4f-48d9-8f2d-17e57f3728bd",
   "metadata": {},
   "source": [
    "- vectors sampled from overlaping distribution generates **morphed** data.\n",
    "    - 潜在空间均匀分布，并且聚类之间没有显著间隙。实际上，看起来相似的数据输入聚类通常在某些区域重叠。\n",
    "- 对 mu 进行的可视化\n",
    "    - 2d：mu[0], mu[1]\n",
    "    - 高维：tsne/umap/pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fc3dd59-e29a-490a-a2d7-e22df84d0213",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-18T14:55:05.779998Z",
     "iopub.status.busy": "2025-01-18T14:55:05.779233Z",
     "iopub.status.idle": "2025-01-18T14:55:05.788824Z",
     "shell.execute_reply": "2025-01-18T14:55:05.787535Z",
     "shell.execute_reply.started": "2025-01-18T14:55:05.779947Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p_xiH7i5QDzATqWdjb4a8w.png\" width=\"600\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p_xiH7i5QDzATqWdjb4a8w.png', width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01576105-faf6-454f-81be-b6c244c1b73e",
   "metadata": {},
   "source": [
    "### coding & viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0a5d523-5605-407c-86bb-0d41792a0854",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T04:32:22.361293Z",
     "iopub.status.busy": "2025-01-19T04:32:22.360760Z",
     "iopub.status.idle": "2025-01-19T04:32:22.368963Z",
     "shell.execute_reply": "2025-01-19T04:32:22.366770Z",
     "shell.execute_reply.started": "2025-01-19T04:32:22.361248Z"
    }
   },
   "outputs": [],
   "source": [
    "# mnist_vae.py\n",
    "# https://github.com/lyeoni/pytorch-mnist-VAE\n",
    "# https://hackernoon.com/how-to-sample-from-latent-space-with-variational-autoencoder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
