{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12ce409a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-01T13:28:56.901453Z",
     "start_time": "2024-03-01T13:28:56.885433Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bd9b6e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-01T13:29:08.995128Z",
     "start_time": "2024-03-01T13:29:08.978791Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.imgur.com/S7KH5hZ.png\" width=\"600\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://i.imgur.com/S7KH5hZ.png', width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e943567c",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbb864d",
   "metadata": {},
   "source": [
    "$$\n",
    "\\nabla_\\theta\\|\\underbrace{\\epsilon}_{\\text{target noise}} - \\underbrace{\\epsilon_\\theta(\\underbrace{\\sqrt{\\bar\\alpha_t}x_0+\\sqrt{1-\\bar\\alpha_t}\\epsilon}_{\\text{noisy image: }x_t}, t)}_{\\text{predict noise}}\\|^2\n",
    "$$\n",
    "\n",
    "- $\\epsilon$: target noise\n",
    "- $\\sqrt{\\bar\\alpha_t}x_0+\\sqrt{1-\\bar\\alpha_t}\\epsilon$: noisy image\n",
    "- $\\epsilon_\\theta(\\cdot, t)$: neural network becomes a **noise predictor**,\n",
    "    - $\\epsilon_\\theta(, t)$：neural Network\n",
    "        - unet\n",
    "- $\\epsilon_\\theta(x_t,t)$：预测的是添加进 $x_t$ 上的 noise（added noise）；\n",
    "    - $t$ 刻画着 noise 的强度；\n",
    "    - Diffusion forward的过程就是构造noise predictor训练集的过程\n",
    "        - input：$x_{t}, t$\n",
    "        - output: $x_{t} - x_{t-1}$\n",
    "- 这个loss是真实误差与预测误差的差的平方；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7917e2",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2920dd",
   "metadata": {},
   "source": [
    "$$\n",
    "x_{t-1}=\\underbrace{\\frac{1}{\\sqrt{\\alpha_t}}\\left(x_t-\\frac{1-\\alpha_t}{\\sqrt{1-\\bar{\\alpha_t}}}\\epsilon_\\theta(x_t,t)\\right)}_{\\mu_\\theta(x_t,t)}+\\underbrace{\\sigma_tz}_{\\text{reparameterize}}\n",
    "$$\n",
    "\n",
    "- $\\epsilon_\\theta(x_t, t)$ unet denoising model\n",
    "    - input: $(x_t, t)$\n",
    "- $\\sigma_tz$：重参数化；    \n",
    "- 右侧部分（不加重参数化的 $\\sigma_tz$），可以视为 $\\mu_\\theta(x_t,t)$（mean predictor，概率分布均值的估计）\n",
    "\n",
    "- 抛开这个 noise （$\\sigma_tz$）不谈，\n",
    "    - $\\epsilon_\\theta(x_t,t)$：预测的是添加进 $x_t$ 上的 noise（added noise）；\n",
    "\n",
    "$$\n",
    "x_{t-1}=\\frac{1}{\\sqrt{\\alpha_t}}\\left(x_t-\\frac{1-\\alpha_t}{\\sqrt{1-\\bar{\\alpha_t}}}\\epsilon_\\theta(x_t,t)\\right)\\\\\n",
    "\\sqrt{\\alpha_t}x_{t-1}+\\frac{1-\\alpha_t}{\\sqrt{1-\\bar\\alpha_t}}\\epsilon_\\theta(x_t,t)=x_t\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329538e5",
   "metadata": {},
   "source": [
    "## coding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1850a97",
   "metadata": {},
   "source": [
    "### training the unet (noise pred) model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c605ab3",
   "metadata": {},
   "source": [
    "```\n",
    "for epoch in range(30):\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        \n",
    "        # x0\n",
    "        clean_images = batch[\"images\"].to(device)\n",
    "        # Sample noise to add to the images\n",
    "        noise = torch.randn(clean_images.shape).to(clean_images.device)\n",
    "        bs = clean_images.shape[0]\n",
    "        \n",
    "        # t\n",
    "        # Sample a random timestep for each image\n",
    "        timesteps = torch.randint(\n",
    "            0, noise_scheduler.num_train_timesteps, (bs,), device=clean_images.device\n",
    "        ).long()\n",
    "        \n",
    "        # scheduler(x0s, epsilons, ts) => xts\n",
    "        # Add noise to the clean images according to the noise magnitude at each timestep\n",
    "        noisy_images = noise_scheduler.add_noise(clean_images, noise, timesteps)\n",
    "        \n",
    "        # unet(xts, ts) => epsilons\n",
    "        # Get the model prediction\n",
    "        noise_pred = unet(noisy_images, timesteps, return_dict=False)[0]\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = F.mse_loss(noise_pred, noise)\n",
    "        loss.backward(loss)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # Update the model parameters with the optimizer\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdf47db",
   "metadata": {},
   "source": [
    "### sampling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdea4c7f",
   "metadata": {},
   "source": [
    "#### pipe.__call__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527db080",
   "metadata": {},
   "source": [
    "```\n",
    "image = randn_tensor(image_shape, generator=generator, device=self.device)\n",
    "\n",
    "# set step values\n",
    "self.scheduler.set_timesteps(num_inference_steps)\n",
    "\n",
    "for t in self.progress_bar(self.scheduler.timesteps):\n",
    "    # 1. predict noise model_output\n",
    "    model_output = self.unet(image, t).sample\n",
    "\n",
    "    # 2. compute previous image: x_t -> x_t-1\n",
    "    image = self.scheduler.step(model_output, t, image, generator=generator).prev_sample\n",
    "\n",
    "image = (image / 2 + 0.5).clamp(0, 1)\n",
    "image = image.cpu().permute(0, 2, 3, 1).numpy()\n",
    "if output_type == \"pil\":\n",
    "    image = self.numpy_to_pil(image)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22b4b7e",
   "metadata": {},
   "source": [
    "#### scheduler.step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2d3963",
   "metadata": {},
   "source": [
    "```\n",
    "t = timestep\n",
    "\n",
    "prev_t = self.previous_timestep(t)\n",
    "\n",
    "if model_output.shape[1] == sample.shape[1] * 2 and self.variance_type in [\"learned\", \"learned_range\"]:\n",
    "    model_output, predicted_variance = torch.split(model_output, sample.shape[1], dim=1)\n",
    "else:\n",
    "    predicted_variance = None\n",
    "\n",
    "# 1. compute alphas, betas\n",
    "alpha_prod_t = self.alphas_cumprod[t]\n",
    "alpha_prod_t_prev = self.alphas_cumprod[prev_t] if prev_t >= 0 else self.one\n",
    "beta_prod_t = 1 - alpha_prod_t\n",
    "beta_prod_t_prev = 1 - alpha_prod_t_prev\n",
    "current_alpha_t = alpha_prod_t / alpha_prod_t_prev\n",
    "current_beta_t = 1 - current_alpha_t\n",
    "\n",
    "# 2. compute predicted original sample from predicted noise also called\n",
    "# \"predicted x_0\" of formula (15) from https://arxiv.org/pdf/2006.11239.pdf\n",
    "if self.config.prediction_type == \"epsilon\":\n",
    "    pred_original_sample = (sample - beta_prod_t ** (0.5) * model_output) / alpha_prod_t ** (0.5)\n",
    "elif self.config.prediction_type == \"sample\":\n",
    "    pred_original_sample = model_output\n",
    "elif self.config.prediction_type == \"v_prediction\":\n",
    "    pred_original_sample = (alpha_prod_t**0.5) * sample - (beta_prod_t**0.5) * model_output\n",
    "else:\n",
    "    raise ValueError(\n",
    "        f\"prediction_type given as {self.config.prediction_type} must be one of `epsilon`, `sample` or\"\n",
    "        \" `v_prediction`  for the DDPMScheduler.\"\n",
    "    )\n",
    "\n",
    "# 3. Clip or threshold \"predicted x_0\"\n",
    "if self.config.thresholding:\n",
    "    pred_original_sample = self._threshold_sample(pred_original_sample)\n",
    "elif self.config.clip_sample:\n",
    "    pred_original_sample = pred_original_sample.clamp(\n",
    "        -self.config.clip_sample_range, self.config.clip_sample_range\n",
    "    )\n",
    "\n",
    "# 4. Compute coefficients for pred_original_sample x_0 and current sample x_t\n",
    "# See formula (7) from https://arxiv.org/pdf/2006.11239.pdf\n",
    "pred_original_sample_coeff = (alpha_prod_t_prev ** (0.5) * current_beta_t) / beta_prod_t\n",
    "current_sample_coeff = current_alpha_t ** (0.5) * beta_prod_t_prev / beta_prod_t\n",
    "\n",
    "# 5. Compute predicted previous sample µ_t\n",
    "# See formula (7) from https://arxiv.org/pdf/2006.11239.pdf\n",
    "pred_prev_sample = pred_original_sample_coeff * pred_original_sample + current_sample_coeff * sample\n",
    "\n",
    "# 6. Add noise\n",
    "variance = 0\n",
    "if t > 0:\n",
    "    device = model_output.device\n",
    "    variance_noise = randn_tensor(\n",
    "        model_output.shape, generator=generator, device=device, dtype=model_output.dtype\n",
    "    )\n",
    "    if self.variance_type == \"fixed_small_log\":\n",
    "        variance = self._get_variance(t, predicted_variance=predicted_variance) * variance_noise\n",
    "    elif self.variance_type == \"learned_range\":\n",
    "        variance = self._get_variance(t, predicted_variance=predicted_variance)\n",
    "        variance = torch.exp(0.5 * variance) * variance_noise\n",
    "    else:\n",
    "        variance = (self._get_variance(t, predicted_variance=predicted_variance) ** 0.5) * variance_noise\n",
    "\n",
    "pred_prev_sample = pred_prev_sample + variance\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a545573",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{split}\n",
    "&x_0\\approx \\hat x_0 = (x_t-\\sqrt{1-\\bar\\alpha_t}\\epsilon_\\theta(x_t))\\sqrt{\\bar\\alpha_t},\\quad (15)\\\\\n",
    "&q(x_{t-1}|x_t,x_0)=\\mathcal N(x_{t-1};\\tilde\\mu_t(x_t,x_0),\\tilde\\beta_tI),\\quad (6)\\\\\n",
    "&\\tilde\\mu_t(x_t,x_0):=\\frac{\\sqrt{\\bar{\\alpha}_{t-1}}\\beta_t}{1-\\bar\\alpha_t}x_0+\\frac{\\sqrt{\\alpha_t}{(1-\\bar\\alpha_{t-1})}}{1-\\bar\\alpha_t}x_t\\\\\n",
    "&\\tilde\\beta_t:=\\frac{1-\\bar\\alpha_{t-1}}{1-\\bar\\alpha_t}\\beta_t,\\quad (7)\n",
    "\\end{split}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
